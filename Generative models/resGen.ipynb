{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSQb730D7DCj",
        "outputId": "f3135ce0-546d-43ca-9127-556d904eb331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ResGen'...\n",
            "remote: Enumerating objects: 338, done.\u001b[K\n",
            "remote: Counting objects: 100% (338/338), done.\u001b[K\n",
            "remote: Compressing objects: 100% (268/268), done.\u001b[K\n",
            "remote: Total 338 (delta 147), reused 239 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (338/338), 15.99 MiB | 6.34 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HaotianZhangAI4Science/ResGen.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72FA0sT3VGUT",
        "outputId": "a71afca7-877b-458d-a5e3-4419c65c365a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.2.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.0%2Bcu118-cp310-cp310-linux_x86_64.whl (811.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.7/811.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0+cu118) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.2.0+cu118)\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.0+cu118)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0+cu118) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0+cu118) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.0+cu118 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0+cu118 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.0+cu118 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric==2.2.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeTxy0vzX7Ak",
        "outputId": "bdbcaa26-f0ce-4053-fe81-15955d8c621b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric==2.2.0\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/565.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/565.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.2.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.2.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.2.0) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.2.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.2.0) (3.5.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773277 sha256=c65b1f68d0014b749687060429b4d7883f34f0536310ebd1dd2213615d49e2fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/e4/83/5e964867e23f8a61cb8c5d5b9477617b710e96e6ebf1844562\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMGY0vgLVX34",
        "outputId": "7d3fe48a-5013-4197-9c88-17bb60d80743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_scatter-2.1.2%2Bpt22cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_sparse-0.6.18%2Bpt22cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_cluster-1.6.3%2Bpt22cu118-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt22cu118-cp310-cp310-linux_x86_64.whl (899 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.2/899.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt22cu118 torch-scatter-2.1.2+pt22cu118 torch-sparse-0.6.18+pt22cu118 torch-spline-conv-1.2.2+pt22cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BwqUQlK-tuQ",
        "outputId": "6a3538a9-7363-4746-ad96-d085ea3cffb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.3-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.3\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.84\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (1.13)\n",
            "Collecting python-lmdb\n",
            "  Downloading python-lmdb-1.0.0b1.tar.gz (8.1 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "# Instalar RDKit\n",
        "!pip install rdkit\n",
        "\n",
        "# Instalar Biopython\n",
        "!pip install biopython\n",
        "\n",
        "# Instalar PyYAML, easydict y python-lmdb\n",
        "!pip install pyyaml easydict python-lmdb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWVQIq6lYML-",
        "outputId": "5aee15d1-7b6f-4a80-e838-7d6cb4e037a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/294.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSB-aSZBzaSj",
        "outputId": "9e8fe24e-1697-4589-8bcb-6db3c6bf7f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ResGen\n"
          ]
        }
      ],
      "source": [
        "%cd ResGen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gpAzN-mzhqB",
        "outputId": "3aaaf16e-9ef8-4eba-81bf-bf678e956bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Zen of Python, by Tim Peters\n",
            "\n",
            "Beautiful is better than ugly.\n",
            "Explicit is better than implicit.\n",
            "Simple is better than complex.\n",
            "Complex is better than complicated.\n",
            "Flat is better than nested.\n",
            "Sparse is better than dense.\n",
            "Readability counts.\n",
            "Special cases aren't special enough to break the rules.\n",
            "Although practicality beats purity.\n",
            "Errors should never pass silently.\n",
            "Unless explicitly silenced.\n",
            "In the face of ambiguity, refuse the temptation to guess.\n",
            "There should be one-- and preferably only one --obvious way to do it.\n",
            "Although that way may not be obvious at first unless you're Dutch.\n",
            "Now is better than never.\n",
            "Although never is often better than *right* now.\n",
            "If the implementation is hard to explain, it's a bad idea.\n",
            "If the implementation is easy to explain, it may be a good idea.\n",
            "Namespaces are one honking great idea -- let's do more of those!\n",
            "Num of parameters is 37.52M\n",
            "/content/ResGen/utils/feats/protein.py:69: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
            "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
            "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:63.)\n",
            "  n_2 = _normalize(torch.cross(u_2, u_1), dim=-1)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "Start to generate in the ./examples/4iiy.pdb\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "successfully generate: CC(=O)O\n",
            "successfully generate: CC(=O)CO\n",
            "successfully generate: CC(O)CCO\n",
            "successfully generate: O=C1C=CC(O)CC1\n",
            "successfully generate: Oc1cccc(O)c1\n",
            "successfully generate: O=C1C=C=C(O)C=C1\n",
            "successfully generate: O=C1C=CC(O)=CC1\n",
            "successfully generate: Nc1cc[nH]c(=O)c1\n",
            "successfully generate: O=C(O)CC(O)CO\n",
            "successfully generate: O=C(O)c1ccccc1\n",
            "successfully generate: OCc1cccc(O)c1\n",
            "successfully generate: NC(=O)c1ccccc1\n",
            "successfully generate: OCc1ccccc1O\n",
            "successfully generate: NC(=O)c1cccnc1\n",
            "successfully generate: OCC(O)CC(O)CO\n",
            "successfully generate: O=c1cc(CO)cc[nH]1\n",
            "successfully generate: C=CCCCCC(=O)O\n",
            "successfully generate: CCc1ccccc1O\n",
            "successfully generate: O=C(O)C1=CC=C(O)CC1\n",
            "successfully generate: O=C1C=CCC(C(=O)O)=C1\n",
            "successfully generate: O=C(O)c1ccc(O)cc1\n",
            "successfully generate: NC(=O)c1ccc(N)nc1\n",
            "successfully generate: O=C1C=CCC(C(O)O)=C1\n",
            "successfully generate: O=C(O)c1ccccc1O\n",
            "successfully generate: O=C(O)Cc1ccc(O)cc1\n",
            "successfully generate: O=c1ccc2ccccc2[nH]1\n",
            "successfully generate: O=C(O)c1ccc(O)c(F)c1\n",
            "successfully generate: O=C(O)c1ccc(C(=O)O)cc1\n",
            "successfully generate: O=C1C=C2CC=CC=C2C(=O)N1\n",
            "successfully generate: CC(=O)N1CC(O)C(O)C(O)C1\n",
            "successfully generate: CNC(=O)c1ccc(C(=O)O)cc1\n",
            "successfully generate: CC=CCCc1cccc(CO)c1\n",
            "successfully generate: Nc1cc(O)c(CC(=O)O)cc1C=O\n",
            "successfully generate: CC=CCCc1cccc(C(=O)O)c1\n",
            "successfully generate: OCC(CO)OCc1ccc(O)cc1\n",
            "successfully generate: O=C(O)CNCc1cccc(C(=O)O)c1\n",
            "successfully generate: O=C(O)C1OC(O)C(O)c2ccc(O)cc21\n",
            "successfully generate: Nc1ncc(Cc2ccccc2)cc1C=O\n",
            "successfully generate: CC1=C2C(=O)N=C(CC(=O)O)C=C2CC=C1\n",
            "successfully generate: CN1CC2C(O)C(O)C(O)C(O)C2CC1=O\n",
            "successfully generate: O=c1ccncn1C1COC(O)C(CO)C1O\n",
            "successfully generate: O=C(O)CNCc1cc(C(=O)O)c(O)cc1O\n",
            "successfully generate: O=CC1CCc2cc3ccccc3cc2C(=O)N1\n",
            "successfully generate: O=C(O)CNC(=O)CC(C(=O)O)c1cccc(O)c1\n",
            "successfully generate: O=C(O)C(O)OCc1ccc(O)cc1C(O)C(=O)O\n",
            "successfully generate: OCCc1cccc(CCc2cc(O)c(O)c(O)c2)c1\n",
            "successfully generate: Cn1cc(CO)c(CCc2ccc(CO)cc2O)cc1=O\n",
            "successfully generate: CC=CC=C1CC2(C)C=CC(=O)CC2CC1CCC=CCO\n",
            "successfully generate: CC1(CO)CC(CO)CC(N2CCc3ccc(O)cc3C2)C1\n",
            "successfully generate: CC(O)=C1CNC(C2CN=C(N)C3CC(C(=O)O)CC32)C(=O)C1\n",
            "successfully generate: O=C(O)C1CC2=CC=CC(C3CC4CCCC(=O)C4CN3)C2C1\n",
            "successfully generate: Oc1cc(C2C3CC(O)CC(O3)C(O)C2O)cc2c(O)cccc12\n",
            "successfully generate: CC1(O)C=CC2=C(CCc3cc(O)c(O)c(c3)OCC3COC(C3)O2)C1\n",
            "successfully generate: CC1CC2(O)CC(=CCO)C(CCc3ccccc3CO)CC2CC1=O\n",
            "successfully generate: CC1(Cn2cnc3c2CC(CO)OC3)OC(c2ccccc2)C(O)C1=O\n",
            "successfully generate: CC(C)=C(CCC(=O)O)Cc1ccc2c(cnc3c(CO)cccc32)c1\n",
            "successfully generate: O=c1[nH]ccc2c1ncn2CC1(CO)OC(c2cccc(O)c2)C(O)C1O\n",
            "successfully generate: O=C(O)CC1CC(C(=O)O)CCC1OC1CCC(C(=O)O)CC1CCCO\n",
            "successfully generate: CCCOC1C(O)C(O)OC(COc2ccc(OC)c(O)c2C(=O)O)C1O\n",
            "successfully generate: OCC1OCC2(CN3C=NC(C(O)O)C13)OC(c1cccc(O)c1)C(O)C2O\n",
            "successfully generate: CC1CC2(O)c3ccccc3C(CCc3ccccc3CO)C(=O)C2CC1=O\n",
            "successfully generate: CC1CC2(O)CC(=CC(=O)O)C(CCc3cc(O)ccc3CO)CC2CC1=O\n",
            "successfully generate: Cc1cnc2c(c1CC1=CCC3=CC(CO)=NC(=O)C3C1)CC(C(=O)O)NC2\n",
            "successfully generate: Nc1ncc2c3c1ncn3CC1(COC2)OC(c2cccc(O)c2)C(O)C1O\n",
            "successfully generate: CC1CC2(O)c3ccccc3C(CCc3cc(O)ccc3CO)CC2CC1=O\n",
            "successfully generate: CC=C1C(CCc2ccccc2CCO)C(O)C2CC(=O)CCC2(C)C1CC(=O)O\n",
            "successfully generate: O=Cc1c2c(cc3c1OCCO3)CCOC(C(O)C1COC(O)CC(OCCO)O1)O2\n",
            "successfully generate: Cc1cnc(C(=O)O)c(CC(=O)O)c1Cc1ccc2cc(C(=O)O)ncc2c1C(=O)O\n",
            "successfully generate: COc1cccc(CCC2C3=CC=CC(C(=O)O)C3C3(C)CCC(=O)CC3C2O)c1CO\n",
            "successfully generate: Cc1c(O)ccc(CC(=O)O)c1Cc1ccc2c(N(O)CC(=O)O)cccc2c1C(=O)O\n",
            "successfully generate: CC(CC(N)=O)=C1CC2(C)C=C(O)C(=O)CC2CC1CCc1ccccc1CCC(=O)O\n",
            "successfully generate: CC(Cc1ccccc1)=C1CC2(C)CC(O)C(=O)CC2CC1CCc1ccccc1CO\n",
            "successfully generate: CC(Cc1ccccc1)=C1CC2(C)CC(O)C(=O)CC2CC1CCc1cc(O)ccc1CO\n",
            "successfully generate: Cc1cncc(-c2ccccc2O)c1Cc1ccc2c(c1C(=O)O)C=CCC2OC(F)CO\n",
            "successfully generate: Cc1c(O)cc(O)c(CC=CC(=O)O)c1Cc1ccc2c(c1C(=O)O)CNC(C(=O)O)C2O\n",
            "successfully generate: CC12CC(O)C(=O)CC1C(=O)C(CCc1ccccc1CO)C(=CC1C=CC(=O)CC1)C2=O\n",
            "successfully generate: Cc1c(O)cc(O)c(CC(=O)O)c1Cc1ccc2c(N(C)CC(C)O)nccc2c1C(=O)O\n",
            "successfully generate: Cc1cnc(C(=O)O)c(CC(=O)O)c1Cc1ccc2c(CO)c(C(C)O)ncc2c1C(=O)O\n",
            "successfully generate: CC(C)=CCOC1C(c2ccccc2)OC(C)(Cn2cnc3c2CC2(COC(O)C2)OC3)C1O\n",
            "successfully generate: Cc1cncc(Cc2cc(O)ccc2O)c1Cc1ccc(C(O)C(O)C(O)CO)cc1C(=O)O\n",
            "successfully generate: COc1ccc(O)c(-c2cccc(C)c2Cc2ccc(C(CC(=O)O)C(N)=O)cc2C(=O)O)c1\n",
            "successfully generate: CC12CC(O)C(=O)CC1C(=O)C(CCc1cc(O)ccc1CO)C(=CC1C=CC(=O)CC1)C2=O\n",
            "successfully generate: COc1cc(C(=O)O)cc(-c2cncc(C)c2CC2=CCc3c(cnc4c3CCCC4)C2=O)c1\n",
            "successfully generate: CC1(CC(=O)O)Cc2c(ncn2CC2(C)OC(c3ccccc3)C(OCC=CCO)C2O)CO1\n",
            "successfully generate: CC12CC(=C(Cc3ccccc3)C(=O)O)C(CCc3ccccc3CO)CC1CC(=O)C(O)C2\n",
            "successfully generate: Cc1c(O)cc(O)c(CC(=O)O)c1Cc1ccc2c(-n3cccc3)c(C(C)N)ccc2c1C(=O)O\n",
            "successfully generate: Cc1cncc(-c2cc(O)c(O)cc2O)c1Cc1ccc(C(CC(=O)O)CC(=O)O)cc1C(=O)O\n",
            "successfully generate: CC12CCC(=O)CC1C(=O)C(CCc1cccc3cc(C(=O)O)ccc13)C1=CCCC(C(=O)O)C12\n",
            "successfully generate: CC12CCC(=O)CC1C(O)C(CCc1cccc3nc(C(=O)O)ccc13)C1=CCCC(C(=O)O)C12\n",
            "successfully generate: Cc1cnc(C)c(Cc2cccc(C(=O)O)c2)c1Cc1ccc2c(c1)C(=O)NCC2(C)CC(=O)O\n",
            "successfully generate: CC12CC(=CCC3=CC=CC3=O)C(CCc3cc(O)cc(O)c3CC(=O)O)CC1CC(=O)C(O)C2\n",
            "successfully generate: CC12CCC(=O)CC1C(O)C(CCc1cccc3cc(C(=O)O)ccc13)C1=CCCC(C(=O)O)C12\n",
            "successfully generate: COc1ccc(O)c(-c2cncc(C(=O)O)c2Cc2ccc(C3CCCC(=O)C3)cc2C(=O)O)c1\n",
            "successfully generate: C=CCC(c1cnc(O)c(C)c1Cc1ccc2c(c1C(=O)O)C=CC(O)C2CO)N(O)C(=O)CO\n",
            "successfully generate: Cc1cccc(-c2cc(O)c(O)cc2O)c1Cc1ccc(C(CC(=O)O)CC(=O)O)cc1C(=O)O\n",
            "successfully generate: Cc1cnc(C(=O)O)c(CC(=O)O)c1Cc1ccc2c(CO)c(C(O)C(=O)O)ncc2c1C(=O)O\n",
            "successfully generate: CCCCCOC(CCCNCCO)OC(COP(=O)(O)O)Oc1oc2c(C(=O)O)cccc2c1C\n",
            "successfully generate: Cc1c(O)nc2c(c1Cc1ccc3c(c1)CNC(C(=O)O)C3NCC(=O)O)CCN(CC(=O)O)C2=O\n",
            "successfully generate: Cc1c(O)cc(O)c(Cc2ccccc2)c1Cc1ccc2c(c1C=O)CNC1(C)CC(C)(O)COC21\n",
            "successfully generate: Cc1c(O)cc(O)c(Cc2ccccc2)c1Cc1ccc2c(c1C=O)CNC1CC(C)(O)C(O)OC21\n",
            "successfully generate: CCN(C)C(COCC(=O)O)c1c[nH]c(=O)c(C)c1Cc1ccc2c(c1C(=O)O)CC=C(C(=O)O)C2\n",
            "successfully generate: Cc1c(O)ncc(CC(CC(=O)O)C(=O)O)c1Cc1ccc2c(CO)c(CO)c(O)cc2c1C(=O)O\n",
            "successfully generate: CC12CC(O)C(=O)CC1C(=O)C(CCc1cccc(O)c1CO)C(=CC1C=C(C(=O)O)CCC1)C2=O\n",
            "successfully generate: CCc1c(CCC2CC3CC(=O)C(O)CC3(C)CC2=C(C)CC2=CC=CC2)cccc1OCC(=O)O\n",
            "successfully generate: COC1(C)COC2c3ccc(Cc4c(C)c(O)cc(O)c4Cc4ccccc4)c(C=O)c3CNC2C1\n",
            "Thanks to use ResGen\n"
          ]
        }
      ],
      "source": [
        "!python gen.py --pdb_file ./examples/4iiy.pdb --sdf_file ./examples/4iiy_ligand.sdf --outdir ./examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOEAec1Hzmfq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}